# Churn Prediction with MLflow Tracking

## ğŸ“‘ Table of Contents

- [About the Project](#about-the-project)
- [Project Structure](#project-structure)
- [Setup Instructions](#setup-instructions)
- [Experimentation with MLflow](#experimentation-with-mlflow)
- [Model Selection & Results](#model-selection--results)
- [Staging vs Production Justification](#staging-vs-production-justification)
  

---

## ğŸ“Œ About the Project

This project demonstrates a full MLOps workflow for a **churn prediction** task. It includes:
- Model experimentation with scikit-learn  
- MLflow logging (parameters, metrics, models, input/output schema)  
- Model versioning and lifecycle management  
- Environment and dependency management with `venv`  
- Clear separation of research code on the `research` branch  

**Dataset**: Synthetic bank customer data with features like age, balance, credit score, etc.

---

## ğŸ“ Project Structure
```bash
MLOps-Course-Labs/
â”œâ”€â”€ churn_prediction/   # Virtual environment (untracked)
â”œâ”€â”€ data/               # Contains CSV dataset
â”œâ”€â”€ mlruns/             # MLflow run logs
â”œâ”€â”€ mlartifacts/         # MLflow artifact store
â”œâ”€â”€ src/
  â””â”€â”€ preprocessing.py
  â””â”€â”€ model.py
â”‚ â””â”€â”€ main.py
â”œâ”€â”€ transformer.pkl       # Saved transformer for preprocessing
â”œâ”€â”€ plot_confusion_matrix.png       # Evaluation visualization
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```


---

## âš™ï¸ Setup Instructions

1. **Clone and switch to the research branch**

```bash
git clone https://github.com/SaraElwatany/MLOps-Course-Labs.git
cd MLOps-Course-Labs
git checkout research
```


2. **Create and activate virtual environment**

```bash
python -m venv churn_prediction
churn_prediction\Scripts\activate  # On Windows
```


3. **Install dependencies**

```bash
pip install -r requirements.txt
```


4. **Run training script**
   
python src/main.py




---

## ğŸ”¬Experimentation with MLflow

Multiple experiments were run and tracked:

- Model type and hyperparameters

- Accuracy, precision, recall, and F1-score

- Confusion matrix visualizations

- Input and output schema using mlflow.models.infer_signature


Tracked models:

- Logistic Regression

- Random Forest
  


---

## ğŸ“Š Model Selection & Results

| Model              | Accuracy | Precision | Recall | F1 Score |
|-------------------|----------|-----------|--------|----------|
| LogisticRegression| 0.81     | 0.77      | 0.65   | 0.70     |
| RandomForest       | 0.86     | 0.83      | 0.78   | 0.80     |

**Random Forest** achieved the highest accuracy and better recall/f1-score, making it the best candidate for production deployment.




---

## ğŸš¦ Staging vs Production Justification

- âœ… Staging Model: Random Forest

Rationale: Fast training time, easy to interpret, slightly lower performance

Use case: Ideal for testing environments or quick iterations


- ğŸ Production Model: Random Forest

Rationale: Best overall performance and robustness

Use case: Deployed for live predictions in a real-world scenario

Both models were registered and versioned using MLflow Model Registry with proper tagging and descriptions.


